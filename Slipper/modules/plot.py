import gzip, os
import matplotlib.pyplot as plt
import numpy as np

'''
plot.py, handles logic of the 'plot' subcommand
'''

class AnalyseFile:


    def __init__(self, path: str):
        self.path = path

        # stores the sum of each tail type, indices:
        # [0] = no_tail, [1] = polyU, [2] = polyA, 
        # [3] = mixed_AU, [4] = mixed_GC, [5] = other
        self.type_count_arr = np.zeros(6, dtype=np.uint32)

        # stores the number of rows in input
        self.row_count = 0

        # initiate dict for storing type counts per tail length
        self.type_per_len = {0: np.zeros((6,), dtype=int)}
        
        # used for easier to understand array indexing
        self.type_codes = {"no_tail": 0, "polyU": 1, 
                           "polyA": 2, "mixed_AU": 3,
                           "mixed_GC": 4, "other": 5}

    # === File handling methods ===

    def _get_header(self):
        '''
        Internal method, used for reading the header of input text file.

        Args:
            handle: file handle generated by one of the open(file, 'r')
                variants, eg. gzip.open(file, 'rt')

        Returns:
            list[str, ...]: header as a \t separated list of strings
        '''
        return self.handle.readline().strip().split('\t')

    def open_gzip(self):
        '''
        Opens a gzipped file for reading as text and stores its 1st line
        (header) separately
        '''
        self.handle = gzip.open(self.path, "rt")
        self.header = self._get_header()

    def open_plain(self):
        '''
        Opens a plain text file for reading and stores its 1st line (header)
        separately
        '''
        self.handle = open(self.path, 'r')
        self.header = self._get_header()

    def close(self):
        '''
        For closing the file after reading
        '''
        self.handle.close()

    def _line_process(self, line):
        '''
        Used for processing the input lines into manageable data structures (only lists for now)
        '''
        return line.strip().split('\t')

    def __iter__(self):
        '''
        Return object iterator
        '''
        return self

    def __next__(self):
        '''
        Define how to get the next element, i.e. line
        '''
        line = self.handle.readline()
        self.line = self._line_process(self.handle.readline())
        if line:
            self.line = self._line_process(line)
            self.row_count += 1
            self._count_type()
            self._type_len()
        else:
            raise StopIteration

    # === Statistic calculation methods ===

    def _count_type(self) -> None:
        '''
        Tick the appropriate tail type counter by 1. Value are stored as
        np.uint32 in a shape (6,) np array. Indice-value pairs are as follows:
        [0] = no_tail, [1] = polyU, [2] = polyA,
        [3] = mixed_AU, [4] = mixed_GC, [5] = other
        '''
        # 13th column stores the tail type
        type = self.line[13]

        match type:
            case "no_tail":
                self.type_count_arr[0] += 1
            case "polyU":
                self.type_count_arr[1] += 1
            case "polyA":
                self.type_count_arr[2] += 1
            case "mixed_AU":
                self.type_count_arr[3] += 1
            case "mixed_GC":
                self.type_count_arr[4] += 1
            case "other":
                self.type_count_arr[5] += 1

    def tail_perc(self) -> np.ndarray:
        '''
        Calculate the percentage of reads with each tail type

        Returns:
            np.ndarray: shape (6,) float64 array with values between 0 and 100
                representing percentages
        '''
        return self.type_count_arr / self.row_count * 100

    def _type_len(self):
        '''
        Calculate the percent of reads of certain type and specific length.
        Those are stored inside a dict with tail lengths as keys and shape (6,)
        int arrays for type counters. Internat method, not supposed to be used
        outside of __next__()
        '''
        tail_len = int(self.line[7])
        tail_type = self.line[13]

        if tail_len not in self.type_per_len:
            self.type_per_len[tail_len] = np.zeros((6,), dtype=int)

        self.type_per_len[tail_len][self.type_codes[tail_type]] += 1

        return None

    def type_len_counts(self, type: int):
        '''
        Transform type_per_len dictionary into X Y arrays that can be used for
        ploting
        '''
        idxs = np.arange
        X, Y = (np.array(list(self.type_per_len.keys())),
                np.array(list(self.type_per_len.values())))
        Y = Y[:, type]

        return X, Y

def plot(filenames: list[str, ...], values: np.ndarray, out_dir: str) -> None:
    '''
    Make plots from calculated statistics.
    This function is the main() od plotting. In the future each specific plot
    should have their own function, and plot() should ONLY be used for
    coordinating them

    Args:
        filenames (list[str, ...]): list of filenames to be used as xticks,
            probably will be changed to "experiment_names" in the next minor
            refactor
        values (np.ndarray): 2D array of float64s, rows represent tail types,
            columns represent filenames/experimental setups
        out_dir (str): directory where plots will be saved
    
    Returns:
        None
    '''

    # tail types taken into account
    types = ("no_tail", "polyU", "polyA", "mixed_AU", "mixed_GC", "other")

    # Percentage arrays are stored under their respective tail type keys
    data = {tail_type: perc_arr for tail_type, perc_arr in zip(types, values)}

    # plot bar width

    width = 0.5

    # === Stacked barplot ===
    # === log Y scale ===

    bottom = np.zeros(len(filenames))

    for label, value in data.items():
        plt.bar(filenames, value, width, label=label, bottom=bottom)
        bottom += value

    plt.title("Tail type percentage")
    plt.xlabel("Tested groups")
    plt.ylabel("Log(Tail type %)")
    plt.semilogy()
    plt.xticks(filenames, rotation = 45)

    plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))
    plt.tight_layout()  # helps avoid clipping
 
    plt.savefig(out_dir + "plottest_log.png", dpi=300)

    plt.clf()

    # === linear Y scale ===

    bottom = np.zeros(len(filenames))

    for label, value in data.items():
        plt.bar(filenames, value, width, label=label, bottom=bottom)
        bottom += value

    plt.title("Tail type percentage")
    plt.xlabel("Tested groups")
    plt.ylabel("Tail type %")
    plt.xticks(filenames, rotation = 45)

    plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))
    plt.tight_layout()  # helps avoid clipping

    plt.savefig(out_dir + "plottest.png", dpi=300)

    return None

def plot_type_len(X: np.ndarray, Y: np.ndarray, total: int) -> None:

    plt.title("Type % per tail length")
    plt.plot(X, Y / total * 100)
    plt.xlabel("tail length (nt)")
    plt.ylabel("% of total")
    plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))
    plt.tight_layout()

    plt.show()

    return None

def ploter(infiles: list[str, ...], out_dir: str) -> None:
    '''
    Plot figures for input files generated by Slipper analyse. For now only
    tail type percent per input file is available

    Args:
        infiles (list[str, ...]): list of filenames or paths to tsv.gz files
            generated by Slipper analyse
        out_dir (str): directory where plots will be saved, has a default value
            handled by argparse

    Returns:
        None
    '''

    files = {i: (path, AnalyseFile(path)) for i, path in zip(range(len(infiles)), infiles)}
    filenames = [filename[0].split('/')[-1] for filename in files.values()]

    # create directory where plots will be saved
    out_dir = os.getcwd() + '/' + out_dir + '/'
    os.makedirs(out_dir, exist_ok=True)
    
    print(f"Plots will be saved in: {out_dir}")

    for file in files.values():

        # remember 
        # file = (rath, AnalyseFile(path))
        # open gziped file for reading
        file[1].open_gzip()

        # counting rows and tail_type occurences is handled by
        # AnalyseFile.__next__() method
        for _ in file[1]:
            pass
        
        file[1].close()

    # AnalyseFile.tail_perc() calculates the relative frequency of each tail
    # type per input file
    percs = np.vstack([file[1].tail_perc() for file in files.values()]).transpose()

    for file in files.values():
        for i in range(6):
            #print(file[1].type_per_len)
            print(file[1].type_len_counts(i))

    # run the main plotting function
    plot(filenames=filenames,
         values=percs,
         out_dir=out_dir)
    
    plot_type_len(X=files[0][1].type_len_counts(2)[0], 
                  Y=files[0][1].type_len_counts(2)[1], 
                  total=files[0][1].row_count)
